{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "data = pd.read_csv('DASS/data.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data = data.drop(['major', 'country'], axis=1)\n",
    "\n",
    "# duplicates and  null values\n",
    "data = data.drop_duplicates().dropna()\n",
    "\n",
    "# 3-sigma \n",
    "def three_sigma_filter(data, column):\n",
    "    mean = data[column].mean()\n",
    "    std = data[column].std()\n",
    "    lower_bound = mean - 3 * std\n",
    "    upper_bound = mean + 3 * std\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "data = three_sigma_filter(data, 'testelapse')\n",
    "data = three_sigma_filter(data, 'surveyelapse')\n",
    "\n",
    "# identical answers\n",
    "n = list(range(0, 126, 3)) \n",
    "question_cols = data.columns[n]\n",
    "data = data[~data[question_cols].apply(lambda row: row.nunique() == 1, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(df, questions):\n",
    "    return df[[f'Q{i}A' for i in questions]].sum(axis=1)\n",
    "\n",
    "data['depression_score'] = calculate_scores(data, [3, 5, 10, 13, 16, 17, 21, 24, 26, 31, 34, 37, 38, 42])\n",
    "data['anxiety_score'] = calculate_scores(data, [2, 4, 7, 9, 15, 19, 20, 23, 25, 28, 30, 36, 40, 41])\n",
    "data['stress_score'] = calculate_scores(data, [1, 6, 8, 11, 12, 14, 18, 22, 27, 29, 32, 33, 35, 39])\n",
    "\n",
    "def map_to_levels(score, thresholds):\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        if score <= threshold:\n",
    "            return i\n",
    "    return len(thresholds)\n",
    "\n",
    "data['depression_level'] = data['depression_score'].apply(lambda x: map_to_levels(x, [9, 13, 20, 27]))\n",
    "data['anxiety_level'] = data['anxiety_score'].apply(lambda x: map_to_levels(x, [7, 9, 14, 19]))\n",
    "data['stress_level'] = data['stress_score'].apply(lambda x: map_to_levels(x, [14, 18, 25, 33]))\n",
    "\n",
    "data['total_emotion_level'] = data.apply(lambda row: round((row['depression_level'] + \n",
    "                                                            row['anxiety_level'] + \n",
    "                                                            row['stress_level']) * 11 / 13), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 210\n",
      "[LightGBM] [Info] Number of data points in the train set: 29597, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 35.028246\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 210\n",
      "[LightGBM] [Info] Number of data points in the train set: 29597, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 29.999932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 210\n",
      "[LightGBM] [Info] Number of data points in the train set: 29597, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 35.137852\n",
      "Mean Squared Error: Depression: 0.31043603528589797, Anxiety: 0.39410831537692687, Stress: 0.3750686813590677\n"
     ]
    }
   ],
   "source": [
    "# Multioutput  \n",
    "X = data[[f'Q{i}A' for i in range(1, 43)]]\n",
    "y = data[['depression_score', 'anxiety_score', 'stress_score']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "lgb_regressor = LGBMRegressor(num_leaves=31, learning_rate=0.05, n_estimators=100)\n",
    "model = MultiOutputRegressor(lgb_regressor)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "print(f'Mean Squared Error: Depression: {mse[0]}, Anxiety: {mse[1]}, Stress: {mse[2]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 210\n",
      "[LightGBM] [Info] Number of data points in the train set: 29597, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score -6.684510\n",
      "[LightGBM] [Info] Start training from score -4.533377\n",
      "[LightGBM] [Info] Start training from score -3.447423\n",
      "[LightGBM] [Info] Start training from score -3.016799\n",
      "[LightGBM] [Info] Start training from score -2.781174\n",
      "[LightGBM] [Info] Start training from score -1.689492\n",
      "[LightGBM] [Info] Start training from score -1.778035\n",
      "[LightGBM] [Info] Start training from score -0.709945\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Classification Accuracy: 0.8448205959862153\n",
      "Feature importances: [np.int32(710), np.int32(640), np.int32(424), np.int32(296), np.int32(540), np.int32(654), np.int32(290), np.int32(681), np.int32(733), np.int32(533), np.int32(748), np.int32(660), np.int32(669), np.int32(1011), np.int32(171), np.int32(642), np.int32(559), np.int32(745), np.int32(444), np.int32(414), np.int32(344), np.int32(609), np.int32(98), np.int32(629), np.int32(514), np.int32(677), np.int32(737), np.int32(403), np.int32(669), np.int32(561), np.int32(555), np.int32(849), np.int32(612), np.int32(532), np.int32(736), np.int32(360), np.int32(579), np.int32(441), np.int32(628), np.int32(669), np.int32(288), np.int32(941)]\n"
     ]
    }
   ],
   "source": [
    "# Using Classifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "y_class = data['total_emotion_level']\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.25, random_state=42)\n",
    "\n",
    "gbm_classifier = LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=100)\n",
    "gbm_classifier.fit(X_train_class, y_train_class)\n",
    "\n",
    "y_pred_class = gbm_classifier.predict(X_test_class)\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "print(f'Classification Accuracy: {accuracy}')\n",
    "\n",
    "print('Feature importances:', list(gbm_classifier.feature_importances_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
