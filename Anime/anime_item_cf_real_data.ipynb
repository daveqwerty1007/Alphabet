{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938523f5",
   "metadata": {},
   "source": [
    "\n",
    "# Anime Item‑Based CF Recommender (Full Data Version)\n",
    "\n",
    "In this notebook we upgrade the simple prototype built earlier to work efficiently with the **full MyAnimeList datasets**.  The files are large—`animelist.csv` is ~1.9 GB and `rating_complete.csv` is ~780 MB—so reading them naïvely into memory and creating a dense pivot table will likely exceed the RAM available on most machines.  To make the model scalable we will:\n",
    "\n",
    "* Read only the necessary columns and specify appropriate dtypes to reduce memory usage.\n",
    "* Filter to the `rating_complete.csv` subset (completed and rated anime only) to capture stronger signals.\n",
    "* Build a **sparse user–item matrix** using SciPy rather than a dense DataFrame.\n",
    "* Use `NearestNeighbors` with a cosine metric to compute the top‑`k` similar anime for each title without materialising a full similarity matrix.\n",
    "* Accumulate recommendations on the fly by looking up precomputed neighbours.\n",
    "\n",
    "The end result still returns a list of anime with `MAL_ID`, `Name`, `Score`, `Type`, `Source` and `Synopsis` columns, but it can handle millions of interactions gracefully.  You can adjust the `n_neighbors` parameter for a balance between speed and recommendation quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3571f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ecb5af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime.csv:\n",
      "   MAL_ID                             Name  Score  \\\n",
      "0       1                     Cowboy Bebop   8.78   \n",
      "1       5  Cowboy Bebop: Tengoku no Tobira   8.39   \n",
      "2       6                           Trigun   8.24   \n",
      "3       7               Witch Hunter Robin   7.27   \n",
      "4       8                   Bouken Ou Beet   6.98   \n",
      "5      15                     Eyeshield 21   7.95   \n",
      "\n",
      "                                              Genres            English name  \\\n",
      "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space            Cowboy Bebop   \n",
      "1              Action, Drama, Mystery, Sci-Fi, Space  Cowboy Bebop:The Movie   \n",
      "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen                  Trigun   \n",
      "3  Action, Mystery, Police, Supernatural, Drama, ...      Witch Hunter Robin   \n",
      "4          Adventure, Fantasy, Shounen, Supernatural  Beet the Vandel Buster   \n",
      "5                    Action, Sports, Comedy, Shounen                 Unknown   \n",
      "\n",
      "                      Japanese name  \n",
      "0                         カウボーイビバップ  \n",
      "1                    カウボーイビバップ 天国の扉  \n",
      "2                             トライガン  \n",
      "3  Witch Hunter ROBIN (ウイッチハンターロビン)  \n",
      "4                            冒険王ビィト  \n",
      "5                          アイシールド21  \n",
      "animelist.csv:\n",
      "   user_id  anime_id  rating  watching_status  watched_episodes\n",
      "0        0        67       9                1                 1\n",
      "1        0      6702       7                1                 4\n",
      "2        0       242      10                1                 4\n",
      "3        0      4898       0                1                 1\n",
      "4        0        21      10                1                 0\n",
      "5        0        24       9                1                 5\n",
      "anime_with_synopsis.csv:\n",
      "   MAL_ID                             Name  Score  \\\n",
      "0       1                     Cowboy Bebop   8.78   \n",
      "1       5  Cowboy Bebop: Tengoku no Tobira   8.39   \n",
      "2       6                           Trigun   8.24   \n",
      "3       7               Witch Hunter Robin   7.27   \n",
      "4       8                   Bouken Ou Beet   6.98   \n",
      "5      15                     Eyeshield 21   7.95   \n",
      "\n",
      "                                              Genres  \\\n",
      "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space   \n",
      "1              Action, Drama, Mystery, Sci-Fi, Space   \n",
      "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen   \n",
      "3  Action, Mystery, Police, Supernatural, Drama, ...   \n",
      "4          Adventure, Fantasy, Shounen, Supernatural   \n",
      "5                    Action, Sports, Comedy, Shounen   \n",
      "\n",
      "                                           sypnopsis  \n",
      "0  In the year 2071, humanity has colonized sever...  \n",
      "1  other day, another bounty—such is the life of ...  \n",
      "2  Vash the Stampede is the man with a $$60,000,0...  \n",
      "3  ches are individuals with special powers like ...  \n",
      "4  It is the dark century and the people are suff...  \n",
      "5  Sena is like any other shy kid starting high s...  \n",
      "rating_complete.csv:\n",
      "   user_id  anime_id  rating\n",
      "0        0       430       9\n",
      "1        0      1004       5\n",
      "2        0      3010       7\n",
      "3        0       570       7\n",
      "4        0      2762       9\n",
      "5        0       431       8\n",
      "watching_status.csv:\n",
      "   status         description\n",
      "0       1  Currently Watching\n",
      "1       2           Completed\n",
      "2       3             On Hold\n",
      "3       4             Dropped\n",
      "4       6       Plan to Watch\n"
     ]
    }
   ],
   "source": [
    "# Load only the first few rows (optional, speeds up processing for large files)\n",
    "df = pd.read_csv('anime/anime.csv', nrows=6)  # adjust path and number of rows if needed\n",
    "df1 = pd.read_csv('anime/animelist.csv', nrows=6)\n",
    "df2 = pd.read_csv('anime/anime_with_synopsis.csv', nrows=6)\n",
    "df3 = pd.read_csv('anime/rating_complete.csv', nrows=6)\n",
    "df4 = pd.read_csv('anime/watching_status.csv')\n",
    "\n",
    "# Get the column headers\n",
    "headers = df.columns.tolist()\n",
    "headers1 = df1.columns.tolist()\n",
    "headers2 = df2.columns.tolist()\n",
    "headers3 = df3.columns.tolist()\n",
    "headers4 = df4.columns.tolist()\n",
    "\n",
    "print(\"anime.csv:\")\n",
    "print(df.iloc[:, :6])\n",
    "print(\"animelist.csv:\")\n",
    "print(df1.iloc[:, :6])\n",
    "print(\"anime_with_synopsis.csv:\")\n",
    "print(df2.iloc[:, :6]) \n",
    "print(\"rating_complete.csv:\") \n",
    "print(df3.iloc[:, :6])\n",
    "print(\"watching_status.csv:\")\n",
    "print(df4.iloc[:, :6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80978ba",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Create a sparse user–item matrix\n",
    "\n",
    "To avoid allocating a dense matrix with millions of rows or columns, we map each `user_id` and `anime_id` to contiguous indices and build a SciPy **Compressive Sparse Row (CSR)** matrix.  Each non‑zero element of the matrix stores a rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map user_ids and anime_ids to 0-based indices\n",
    "user_codes = ratings_df['user_id'].astype('category').cat.codes\n",
    "anime_codes = ratings_df['anime_id'].astype('category').cat.codes\n",
    "\n",
    "# Keep track of the mapping back to original IDs (for recommendations)\n",
    "user_id_map = pd.Series(ratings_df['user_id'].unique(), index=np.unique(user_codes))\n",
    "anime_id_map = pd.Series(ratings_df['anime_id'].unique(), index=np.unique(anime_codes))\n",
    "\n",
    "# Build the sparse matrix (users x items)\n",
    "data = ratings_df['score'].astype(np.float32).values\n",
    "user_item_sparse = coo_matrix((data, (user_codes, anime_codes))).tocsr()\n",
    "\n",
    "print('User–item matrix shape:', user_item_sparse.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3586449",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Compute item similarities using NearestNeighbors\n",
    "\n",
    "We compute the top‑`k` similar anime for each title using a cosine distance metric.  This avoids creating a dense similarity matrix.  The parameter `n_neighbors` determines how many neighbours (including itself) are returned for each item.  A value between 20 and 50 is a reasonable starting point for recommendation quality.\n",
    "\n",
    "We transpose the user–item matrix so that items correspond to rows in the matrix passed to `NearestNeighbors`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure the number of neighbours to retrieve\n",
    "n_neighbors = 30  # adjust based on memory and desired diversity\n",
    "\n",
    "# Transpose to get items as rows\n",
    "item_user_sparse = user_item_sparse.T\n",
    "\n",
    "# Fit NearestNeighbors model on sparse item vectors\n",
    "nn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=n_neighbors, n_jobs=-1)\n",
    "\n",
    "print('Fitting NearestNeighbors model...')\n",
    "nn_model.fit(item_user_sparse)\n",
    "\n",
    "# Retrieve neighbours for all items (distances and indices)\n",
    "print('Computing neighbours...')\n",
    "distances, indices = nn_model.kneighbors(item_user_sparse, return_distance=True)\n",
    "\n",
    "print('Computed nearest neighbours for', item_user_sparse.shape[0], 'items')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1eb451",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Define the recommendation function\n",
    "\n",
    "When a new user provides a list of anime they have watched with corresponding scores (like the structure of `animelist.csv` but without `user_id`), we generate candidate recommendations by looking up the precomputed nearest neighbours for each item.  We weight each neighbour by the rating the user gave to the source item, accumulate scores, and then select the top items that the user hasn't already seen.\n",
    "\n",
    "The function below accepts a list of dictionaries with keys `anime_id` and `score`, the neighbour index matrices (`indices` and `distances`), the `anime_id_map`, and the metadata.  It returns a DataFrame of the top `N` recommendations enriched with metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daac8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_anime_full(user_ratings, anime_id_map, indices, distances, metadata, top_n=5):\n",
    "    '''\n",
    "    Recommend anime for a new user using precomputed nearest neighbours.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_ratings : list of dict\n",
    "        Each dict should contain an anime_id and a score. This list represents the past ratings of a user.\n",
    "    anime_id_map : pd.Series\n",
    "        Mapping from internal item index to original anime_id.\n",
    "    indices : ndarray\n",
    "        Precomputed indices of nearest neighbours for each item (output of NearestNeighbors.kneighbors).\n",
    "    distances : ndarray\n",
    "        Precomputed cosine distances for the nearest neighbours.\n",
    "    metadata : pd.DataFrame\n",
    "        Anime metadata with MAL_ID, Name, Score, Type, Source and optionally synopsis.\n",
    "    top_n : int\n",
    "        Number of recommendations to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Recommended titles with metadata and aggregated similarity scores.\n",
    "    '''\n",
    "    # Build a mapping from anime_id to its internal index\n",
    "    id_to_internal = pd.Series(anime_id_map.index, index=anime_id_map.values)\n",
    "\n",
    "    # Convert user_ratings list into a Series for easier lookup\n",
    "    user_series = pd.Series({item['anime_id']: item['score'] for item in user_ratings})\n",
    "\n",
    "    candidate_scores = {}\n",
    "\n",
    "    for anime_id, rating in user_series.items():\n",
    "        if anime_id not in id_to_internal:\n",
    "            continue  # skip unknown anime ids\n",
    "        internal_idx = id_to_internal[anime_id]\n",
    "        neigh_indices = indices[internal_idx]\n",
    "        neigh_distances = distances[internal_idx]\n",
    "\n",
    "        # Convert distances to similarity (1 - distance)\n",
    "        neigh_similarities = 1.0 - neigh_distances\n",
    "\n",
    "        for neigh_internal, sim in zip(neigh_indices, neigh_similarities):\n",
    "            candidate_anime_id = anime_id_map[neigh_internal]\n",
    "            # Skip if the user already rated this anime\n",
    "            if candidate_anime_id in user_series.index:\n",
    "                continue\n",
    "            candidate_scores[candidate_anime_id] = candidate_scores.get(candidate_anime_id, 0.0) + sim * rating\n",
    "\n",
    "    if not candidate_scores:\n",
    "        return pd.DataFrame(columns=['MAL_ID', 'Name', 'Score', 'Type', 'Source', 'similarity_score'])\n",
    "\n",
    "    # Sort candidates by accumulated score\n",
    "    sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    candidate_ids, scores = zip(*sorted_candidates)\n",
    "\n",
    "    # Create a DataFrame with metadata\n",
    "    recs = metadata.set_index('MAL_ID').loc[list(candidate_ids)].reset_index()\n",
    "    recs['similarity_score'] = scores\n",
    "\n",
    "    # Include synopsis column if present\n",
    "    synopsis_cols = [col for col in ['synopsis'] if col in recs.columns]\n",
    "\n",
    "    return recs[['MAL_ID', 'Name', 'Score', 'Type', 'Source'] + synopsis_cols + ['similarity_score']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2aada",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Example usage\n",
    "\n",
    "After fitting the nearest neighbour model and computing the `distances` and `indices` arrays, you can call `recommend_anime_full` with a list of the user's rated anime.  The example below shows the structure of the call.  Replace `input_ratings` with the actual list of anime IDs and scores for your new user.  This code is commented out by default because fitting the model on the full dataset may take several minutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f538526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example user input (replace with real user ratings)\n",
    "input_ratings = [\n",
    "    {'anime_id': 20, 'score': 9},\n",
    "    {'anime_id': 5114, 'score': 8},\n",
    "    {'anime_id': 32281, 'score': 10},\n",
    "]\n",
    "\n",
    "# Generate recommendations (top 5)\n",
    "# recommendations = recommend_anime_full(input_ratings, anime_id_map, indices, distances, anime_meta, top_n=5)\n",
    "# display(recommendations)\n",
    "\n",
    "print(\"To generate recommendations, uncomment the call above once the nearest neighbour model has been fitted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
